{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc50f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pyarrow pillow --upgrade --user\n",
    "# !pip3 install mlflow\n",
    "import pyarrow.parquet as pq\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import mlflow.pytorch\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c7fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4179c944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('MLFLOW_TRACKING_USERNAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0d01fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mateuszgalinski/Documents/Uni/mlops_project/MLOps-TeamBeans/notebooks/2_model_train_validation.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mateuszgalinski/Documents/Uni/mlops_project/MLOps-TeamBeans/notebooks/2_model_train_validation.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m load_dotenv(\u001b[39m'\u001b[39m\u001b[39m.env\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mateuszgalinski/Documents/Uni/mlops_project/MLOps-TeamBeans/notebooks/2_model_train_validation.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Set MLFLOW_TRACKING_USERNAME and MLFLOW_TRACKING_PASSWORD\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mateuszgalinski/Documents/Uni/mlops_project/MLOps-TeamBeans/notebooks/2_model_train_validation.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mMLFLOW_TRACKING_USERNAME\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mMLFLOW_TRACKING_USERNAME\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mateuszgalinski/Documents/Uni/mlops_project/MLOps-TeamBeans/notebooks/2_model_train_validation.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mMLFLOW_TRACKING_PASSWORD\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mMLFLOW_TRACKING_PASSWORD\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/os.py:684\u001b[0m, in \u001b[0;36m_Environ.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, value):\n\u001b[1;32m    683\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)\n\u001b[0;32m--> 684\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencodevalue(value)\n\u001b[1;32m    685\u001b[0m     putenv(key, value)\n\u001b[1;32m    686\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[key] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/os.py:756\u001b[0m, in \u001b[0;36m_createenviron.<locals>.encode\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(value):\n\u001b[1;32m    755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 756\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstr expected, not \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    757\u001b[0m     \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39mencode(encoding, \u001b[39m'\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('.env')\n",
    "\n",
    "# Set MLFLOW_TRACKING_USERNAME and MLFLOW_TRACKING_PASSWORD\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = os.getenv('MLFLOW_TRACKING_USERNAME')\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = os.getenv('MLFLOW_TRACKING_PASSWORD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ffdb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"CNN-pytorch\")\n",
    "mlflow.pytorch.autolog\n",
    "mlflow.set_tracking_uri('https://dagshub.com/wwoszczek/MLOps-TeamBeans.mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebeaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(f\"run_id: {r.info.run_id}\")\n",
    "    print(f\"artifacts: {artifacts}\")\n",
    "    print(f\"params: {r.data.params}\")\n",
    "    print(f\"metrics: {r.data.metrics}\")\n",
    "    print(f\"tags: {tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43873a",
   "metadata": {},
   "source": [
    "#### Copying the class of CustomDataset as it cannot be imported easily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7235c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa453f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_file_path', 'image', 'labels'],\n",
       "    num_rows: 1034\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "dataset_train = Dataset.from_file(os.path.join(current_directory, \"raw\\\\train\\\\\") + \"data-00000-of-00001.arrow\")\n",
    "\n",
    "dataset_validation = Dataset.from_file(os.path.join(current_directory, \"raw\\\\validation\\\\\") + \"data-00000-of-00001.arrow\")\n",
    "\n",
    "dataset_test = Dataset.from_file(os.path.join(current_directory, \"raw\\\\test\\\\\") + \"data-00000-of-00001.arrow\")\n",
    "\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3b6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((500,500)),  # Resize to our desired size\n",
    "            transforms.ToTensor(),          # Convert PIL Image to PyTorch tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize RGB channels\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        image = self.transform(sample['image'])\n",
    "        label = sample['labels']\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "custom_train = CustomDataset(dataset_train)\n",
    "custom_validation = CustomDataset(dataset_validation)\n",
    "custom_test = CustomDataset(dataset_test)\n",
    "\n",
    "# Create a DataLoader for training, validation and test\n",
    "train_loader = DataLoader(custom_train, batch_size=32, shuffle=True)    \n",
    "validation_loader = DataLoader(custom_validation, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(custom_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc10e0",
   "metadata": {},
   "source": [
    "#### End of the copied part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bada0173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataLoader from the file\n",
    "train_loader = torch.load('dataloaders/train_loader.pt')\n",
    "validation_loader= torch.load('dataloaders/validation_loader.pt')\n",
    "test_loader = torch.load('dataloaders/test_loader.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a575ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5218723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 500, 500]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "  print(images.size(), labels.size())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a330afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNNReducedStride10(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(SimpleCNNReducedStride10, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout for regularization\n",
    "        \n",
    "        # Calculate the correct input size for fc1 based on the spatial dimensions\n",
    "        self.fc1_input_size = self.calculate_fc1_input_size()\n",
    "        self.fc1 = nn.Linear(250000, 256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(0.5)  # Add dropout for regularization\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)  # Softmax activation for classification\n",
    "\n",
    "    def calculate_fc1_input_size(self):\n",
    "        # Assuming the output size after the second convolutional layer\n",
    "        # with stride 10 is (16, 50, 50), calculate the input size for fc1\n",
    "        return 16 * 50 * 50\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten the feature maps\n",
    "        x = self.dropout(x)  # Apply dropout for regularization\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = self.log_softmax(x)  # Apply softmax for classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6eac7b",
   "metadata": {},
   "source": [
    "#### Code Restructured to fit MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2724aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters in the reduced model: 64002419\n",
      "Epoch(0/5 : Batch number(1/33) : Batch loss : 1.1032708883285522\n",
      "Epoch(0/5 : Batch number(2/33) : Batch loss : 8.681683540344238\n",
      "Epoch(0/5 : Batch number(3/33) : Batch loss : 17.68632698059082\n",
      "Epoch(0/5 : Batch number(4/33) : Batch loss : 8.561243057250977\n",
      "Epoch(0/5 : Batch number(5/33) : Batch loss : 9.949642181396484\n",
      "Epoch(0/5 : Batch number(6/33) : Batch loss : 4.945017337799072\n",
      "Epoch(0/5 : Batch number(7/33) : Batch loss : 3.6156113147735596\n",
      "Epoch(0/5 : Batch number(8/33) : Batch loss : 3.332427740097046\n",
      "Epoch(0/5 : Batch number(9/33) : Batch loss : 4.154150009155273\n",
      "Epoch(0/5 : Batch number(10/33) : Batch loss : 1.5108925104141235\n",
      "Epoch(0/5 : Batch number(11/33) : Batch loss : 2.1299262046813965\n",
      "Epoch(0/5 : Batch number(12/33) : Batch loss : 1.7299935817718506\n",
      "Epoch(0/5 : Batch number(13/33) : Batch loss : 1.1807994842529297\n",
      "Epoch(0/5 : Batch number(14/33) : Batch loss : 1.1367098093032837\n",
      "Epoch(0/5 : Batch number(15/33) : Batch loss : 1.5796290636062622\n",
      "Epoch(0/5 : Batch number(16/33) : Batch loss : 1.2422384023666382\n",
      "Epoch(0/5 : Batch number(17/33) : Batch loss : 1.8375763893127441\n",
      "Epoch(0/5 : Batch number(18/33) : Batch loss : 1.1355128288269043\n",
      "Epoch(0/5 : Batch number(19/33) : Batch loss : 1.2434688806533813\n",
      "Epoch(0/5 : Batch number(20/33) : Batch loss : 0.956712007522583\n",
      "Epoch(0/5 : Batch number(21/33) : Batch loss : 1.006404995918274\n",
      "Epoch(0/5 : Batch number(22/33) : Batch loss : 0.9951269626617432\n",
      "Epoch(0/5 : Batch number(23/33) : Batch loss : 0.8358538150787354\n",
      "Epoch(0/5 : Batch number(24/33) : Batch loss : 0.7108297944068909\n",
      "Epoch(0/5 : Batch number(25/33) : Batch loss : 0.7948411703109741\n",
      "Epoch(0/5 : Batch number(26/33) : Batch loss : 0.9880375266075134\n",
      "Epoch(0/5 : Batch number(27/33) : Batch loss : 1.103116512298584\n",
      "Epoch(0/5 : Batch number(28/33) : Batch loss : 0.9436998963356018\n",
      "Epoch(0/5 : Batch number(29/33) : Batch loss : 0.9509903192520142\n",
      "Epoch(0/5 : Batch number(30/33) : Batch loss : 0.7121552228927612\n",
      "Epoch(0/5 : Batch number(31/33) : Batch loss : 0.7780531644821167\n",
      "Epoch(0/5 : Batch number(32/33) : Batch loss : 0.902655839920044\n",
      "Epoch(0/5 : Batch number(33/33) : Batch loss : 0.843122661113739\n",
      "Training loss : 2.70538545738567\n",
      "Epoch(1/5 : Batch number(1/33) : Batch loss : 0.7164531350135803\n",
      "Epoch(1/5 : Batch number(2/33) : Batch loss : 0.84433913230896\n",
      "Epoch(1/5 : Batch number(3/33) : Batch loss : 0.7264676690101624\n",
      "Epoch(1/5 : Batch number(4/33) : Batch loss : 0.7730526924133301\n",
      "Epoch(1/5 : Batch number(5/33) : Batch loss : 0.8316799402236938\n",
      "Epoch(1/5 : Batch number(6/33) : Batch loss : 0.6996071338653564\n",
      "Epoch(1/5 : Batch number(7/33) : Batch loss : 0.7088611721992493\n",
      "Epoch(1/5 : Batch number(8/33) : Batch loss : 0.7557891011238098\n",
      "Epoch(1/5 : Batch number(9/33) : Batch loss : 0.661742091178894\n",
      "Epoch(1/5 : Batch number(10/33) : Batch loss : 0.7758926153182983\n",
      "Epoch(1/5 : Batch number(11/33) : Batch loss : 0.6826629042625427\n",
      "Epoch(1/5 : Batch number(12/33) : Batch loss : 0.6589734554290771\n",
      "Epoch(1/5 : Batch number(13/33) : Batch loss : 0.7329028844833374\n",
      "Epoch(1/5 : Batch number(14/33) : Batch loss : 0.7074632048606873\n",
      "Epoch(1/5 : Batch number(15/33) : Batch loss : 0.46008267998695374\n",
      "Epoch(1/5 : Batch number(16/33) : Batch loss : 0.8158677220344543\n",
      "Epoch(1/5 : Batch number(17/33) : Batch loss : 0.6224381923675537\n",
      "Epoch(1/5 : Batch number(18/33) : Batch loss : 0.5785596370697021\n",
      "Epoch(1/5 : Batch number(19/33) : Batch loss : 0.8406555652618408\n",
      "Epoch(1/5 : Batch number(20/33) : Batch loss : 0.8701523542404175\n",
      "Epoch(1/5 : Batch number(21/33) : Batch loss : 0.7737478017807007\n",
      "Epoch(1/5 : Batch number(22/33) : Batch loss : 0.6214689016342163\n",
      "Epoch(1/5 : Batch number(23/33) : Batch loss : 0.43032968044281006\n",
      "Epoch(1/5 : Batch number(24/33) : Batch loss : 0.8688153624534607\n",
      "Epoch(1/5 : Batch number(25/33) : Batch loss : 0.6485888361930847\n",
      "Epoch(1/5 : Batch number(26/33) : Batch loss : 0.7435466647148132\n",
      "Epoch(1/5 : Batch number(27/33) : Batch loss : 0.6062288284301758\n",
      "Epoch(1/5 : Batch number(28/33) : Batch loss : 0.8433839678764343\n",
      "Epoch(1/5 : Batch number(29/33) : Batch loss : 0.9028590321540833\n",
      "Epoch(1/5 : Batch number(30/33) : Batch loss : 0.6496574282646179\n",
      "Epoch(1/5 : Batch number(31/33) : Batch loss : 0.620677649974823\n",
      "Epoch(1/5 : Batch number(32/33) : Batch loss : 0.5541391968727112\n",
      "Epoch(1/5 : Batch number(33/33) : Batch loss : 0.6620299220085144\n",
      "Training loss : 3.41414656512665\n",
      "Epoch(2/5 : Batch number(1/33) : Batch loss : 0.7680873274803162\n",
      "Epoch(2/5 : Batch number(2/33) : Batch loss : 0.6881250143051147\n",
      "Epoch(2/5 : Batch number(3/33) : Batch loss : 0.5639542937278748\n",
      "Epoch(2/5 : Batch number(4/33) : Batch loss : 0.5731244683265686\n",
      "Epoch(2/5 : Batch number(5/33) : Batch loss : 0.6521667242050171\n",
      "Epoch(2/5 : Batch number(6/33) : Batch loss : 0.4453674852848053\n",
      "Epoch(2/5 : Batch number(7/33) : Batch loss : 0.5074577927589417\n",
      "Epoch(2/5 : Batch number(8/33) : Batch loss : 0.6090017557144165\n",
      "Epoch(2/5 : Batch number(9/33) : Batch loss : 0.4427570402622223\n",
      "Epoch(2/5 : Batch number(10/33) : Batch loss : 0.42178964614868164\n",
      "Epoch(2/5 : Batch number(11/33) : Batch loss : 0.5670689344406128\n",
      "Epoch(2/5 : Batch number(12/33) : Batch loss : 0.867724597454071\n",
      "Epoch(2/5 : Batch number(13/33) : Batch loss : 0.5949164032936096\n",
      "Epoch(2/5 : Batch number(14/33) : Batch loss : 0.4712630808353424\n",
      "Epoch(2/5 : Batch number(15/33) : Batch loss : 0.405327171087265\n",
      "Epoch(2/5 : Batch number(16/33) : Batch loss : 0.4667162001132965\n",
      "Epoch(2/5 : Batch number(17/33) : Batch loss : 0.5803579092025757\n",
      "Epoch(2/5 : Batch number(18/33) : Batch loss : 0.6848177313804626\n",
      "Epoch(2/5 : Batch number(19/33) : Batch loss : 0.7430390119552612\n",
      "Epoch(2/5 : Batch number(20/33) : Batch loss : 0.477294385433197\n",
      "Epoch(2/5 : Batch number(21/33) : Batch loss : 0.48450636863708496\n",
      "Epoch(2/5 : Batch number(22/33) : Batch loss : 0.6221033334732056\n",
      "Epoch(2/5 : Batch number(23/33) : Batch loss : 0.437313437461853\n",
      "Epoch(2/5 : Batch number(24/33) : Batch loss : 0.44688209891319275\n",
      "Epoch(2/5 : Batch number(25/33) : Batch loss : 0.6474802494049072\n",
      "Epoch(2/5 : Batch number(26/33) : Batch loss : 0.44812265038490295\n",
      "Epoch(2/5 : Batch number(27/33) : Batch loss : 0.4498969614505768\n",
      "Epoch(2/5 : Batch number(28/33) : Batch loss : 0.4577668607234955\n",
      "Epoch(2/5 : Batch number(29/33) : Batch loss : 0.5341384410858154\n",
      "Epoch(2/5 : Batch number(30/33) : Batch loss : 0.4984948933124542\n",
      "Epoch(2/5 : Batch number(31/33) : Batch loss : 0.4975794851779938\n",
      "Epoch(2/5 : Batch number(32/33) : Batch loss : 0.44740062952041626\n",
      "Epoch(2/5 : Batch number(33/33) : Batch loss : 0.28478479385375977\n",
      "Training loss : 3.9531413280602656\n",
      "Epoch(3/5 : Batch number(1/33) : Batch loss : 0.26645427942276\n",
      "Epoch(3/5 : Batch number(2/33) : Batch loss : 0.3822498619556427\n",
      "Epoch(3/5 : Batch number(3/33) : Batch loss : 0.48286333680152893\n",
      "Epoch(3/5 : Batch number(4/33) : Batch loss : 0.4721701145172119\n",
      "Epoch(3/5 : Batch number(5/33) : Batch loss : 0.3774716556072235\n",
      "Epoch(3/5 : Batch number(6/33) : Batch loss : 0.30592721700668335\n",
      "Epoch(3/5 : Batch number(7/33) : Batch loss : 0.383953720331192\n",
      "Epoch(3/5 : Batch number(8/33) : Batch loss : 0.45351698994636536\n",
      "Epoch(3/5 : Batch number(9/33) : Batch loss : 0.4506218433380127\n",
      "Epoch(3/5 : Batch number(10/33) : Batch loss : 0.38049691915512085\n",
      "Epoch(3/5 : Batch number(11/33) : Batch loss : 0.2516143321990967\n",
      "Epoch(3/5 : Batch number(12/33) : Batch loss : 0.358243852853775\n",
      "Epoch(3/5 : Batch number(13/33) : Batch loss : 0.4424988329410553\n",
      "Epoch(3/5 : Batch number(14/33) : Batch loss : 0.33301499485969543\n",
      "Epoch(3/5 : Batch number(15/33) : Batch loss : 0.26618292927742004\n",
      "Epoch(3/5 : Batch number(16/33) : Batch loss : 0.19357886910438538\n",
      "Epoch(3/5 : Batch number(17/33) : Batch loss : 0.4412202835083008\n",
      "Epoch(3/5 : Batch number(18/33) : Batch loss : 0.5016187429428101\n",
      "Epoch(3/5 : Batch number(19/33) : Batch loss : 0.2822292745113373\n",
      "Epoch(3/5 : Batch number(20/33) : Batch loss : 0.512408435344696\n",
      "Epoch(3/5 : Batch number(21/33) : Batch loss : 0.6340515613555908\n",
      "Epoch(3/5 : Batch number(22/33) : Batch loss : 0.2084459513425827\n",
      "Epoch(3/5 : Batch number(23/33) : Batch loss : 0.46153324842453003\n",
      "Epoch(3/5 : Batch number(24/33) : Batch loss : 0.48316648602485657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(3/5 : Batch number(25/33) : Batch loss : 0.3181658983230591\n",
      "Epoch(3/5 : Batch number(26/33) : Batch loss : 0.42861124873161316\n",
      "Epoch(3/5 : Batch number(27/33) : Batch loss : 0.47407102584838867\n",
      "Epoch(3/5 : Batch number(28/33) : Batch loss : 0.279560387134552\n",
      "Epoch(3/5 : Batch number(29/33) : Batch loss : 0.4122806191444397\n",
      "Epoch(3/5 : Batch number(30/33) : Batch loss : 0.42252063751220703\n",
      "Epoch(3/5 : Batch number(31/33) : Batch loss : 0.2878819704055786\n",
      "Epoch(3/5 : Batch number(32/33) : Batch loss : 0.3474612236022949\n",
      "Epoch(3/5 : Batch number(33/33) : Batch loss : 0.2461000382900238\n",
      "Training loss : 4.333207594174327\n",
      "Epoch(4/5 : Batch number(1/33) : Batch loss : 0.3796701431274414\n",
      "Epoch(4/5 : Batch number(2/33) : Batch loss : 0.41745495796203613\n",
      "Epoch(4/5 : Batch number(3/33) : Batch loss : 0.2648260295391083\n",
      "Epoch(4/5 : Batch number(4/33) : Batch loss : 0.1686577945947647\n",
      "Epoch(4/5 : Batch number(5/33) : Batch loss : 0.29636791348457336\n",
      "Epoch(4/5 : Batch number(6/33) : Batch loss : 0.213541641831398\n",
      "Epoch(4/5 : Batch number(7/33) : Batch loss : 0.19836147129535675\n",
      "Epoch(4/5 : Batch number(8/33) : Batch loss : 0.24700963497161865\n",
      "Epoch(4/5 : Batch number(9/33) : Batch loss : 0.1970839649438858\n",
      "Epoch(4/5 : Batch number(10/33) : Batch loss : 0.31807687878608704\n",
      "Epoch(4/5 : Batch number(11/33) : Batch loss : 0.18205440044403076\n",
      "Epoch(4/5 : Batch number(12/33) : Batch loss : 0.4058927297592163\n",
      "Epoch(4/5 : Batch number(13/33) : Batch loss : 0.3259117603302002\n",
      "Epoch(4/5 : Batch number(14/33) : Batch loss : 0.19637493789196014\n",
      "Epoch(4/5 : Batch number(15/33) : Batch loss : 0.49265703558921814\n",
      "Epoch(4/5 : Batch number(16/33) : Batch loss : 0.1442953646183014\n",
      "Epoch(4/5 : Batch number(17/33) : Batch loss : 0.28103041648864746\n",
      "Epoch(4/5 : Batch number(18/33) : Batch loss : 0.25425004959106445\n",
      "Epoch(4/5 : Batch number(19/33) : Batch loss : 0.17925505340099335\n",
      "Epoch(4/5 : Batch number(20/33) : Batch loss : 0.1683734506368637\n",
      "Epoch(4/5 : Batch number(21/33) : Batch loss : 0.2818854749202728\n",
      "Epoch(4/5 : Batch number(22/33) : Batch loss : 0.3948926627635956\n",
      "Epoch(4/5 : Batch number(23/33) : Batch loss : 0.23553068935871124\n",
      "Epoch(4/5 : Batch number(24/33) : Batch loss : 0.3465690612792969\n",
      "Epoch(4/5 : Batch number(25/33) : Batch loss : 0.21339797973632812\n",
      "Epoch(4/5 : Batch number(26/33) : Batch loss : 0.2666490375995636\n",
      "Epoch(4/5 : Batch number(27/33) : Batch loss : 0.24389603734016418\n",
      "Epoch(4/5 : Batch number(28/33) : Batch loss : 0.25459203124046326\n",
      "Epoch(4/5 : Batch number(29/33) : Batch loss : 0.2360159456729889\n",
      "Epoch(4/5 : Batch number(30/33) : Batch loss : 0.15842285752296448\n",
      "Epoch(4/5 : Batch number(31/33) : Batch loss : 0.2554202079772949\n",
      "Epoch(4/5 : Batch number(32/33) : Batch loss : 0.12853938341140747\n",
      "Epoch(4/5 : Batch number(33/33) : Batch loss : 0.39554455876350403\n",
      "Training loss : 4.598131883776549\n",
      "Batch (1/5)\n",
      "Batch (2/5)\n",
      "Batch (3/5)\n",
      "Batch (4/5)\n",
      "Batch (5/5)\n",
      "Accuracy of the model on 133 test images: 75.18796992481202% \n",
      "run_id: 8e1dee56666343b0b89fd19dc23dba56\n",
      "artifacts: []\n",
      "params: {'fc1_input_size': '40000', 'stride_conv1': '2', 'kernel_size_conv1': '3', 'kernel_size_conv2': '3', 'activation_function': 'ReLU', 'stride_conv2': '2', 'total_trainable_parameters': '64002419', 'num_epochs': '5', 'num_classes': '3', 'padding_conv1': '1', 'padding_conv2': '1', 'dropout_rate': '0.5', 'num_conv_layers': '2'}\n",
      "metrics: {'test_accuracy': 75.187969924812, 'training_loss': 4.59813188377655}\n",
      "tags: {}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    ## The idea is to get the autolog to run for our pytorch funct. \n",
    "    ## It might depend on the funct. we choose and the pytorch version\n",
    "    ## Thus initially I defined some metrics to try it.\n",
    "    \n",
    "    # Create an instance of the SimpleCNNReduced model\n",
    "    model = SimpleCNNReducedStride10(num_classes=3)\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # Calculate the total number of trainable parameters\n",
    "    total_params_reduced = count_parameters(model)\n",
    "    mlflow.log_param(\"total_trainable_parameters\", total_params_reduced)\n",
    "    print(f\"Total trainable parameters in the reduced model: {total_params_reduced}\")\n",
    "    \n",
    "    ###############################3\n",
    "    \n",
    "    from torch.optim import Adam\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters())\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    num_epochs = 5\n",
    "    batch_loss = 0\n",
    "    cum_epoch_loss = 0\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"num_classes\", 3)\n",
    "    mlflow.log_param(\"kernel_size_conv1\", 3)\n",
    "    mlflow.log_param(\"stride_conv1\", 2)\n",
    "    mlflow.log_param(\"padding_conv1\", 1)\n",
    "    mlflow.log_param(\"kernel_size_conv2\", 3)\n",
    "    mlflow.log_param(\"stride_conv2\", 2)\n",
    "    mlflow.log_param(\"padding_conv2\", 1)\n",
    "    mlflow.log_param(\"dropout_rate\", 0.5)\n",
    "    mlflow.log_param(\"fc1_input_size\", model.fc1_input_size)\n",
    "    mlflow.log_param(\"num_conv_layers\", 2)  # Example: Number of convolutional layers\n",
    "    mlflow.log_param(\"activation_function\", \"ReLU\")  # Example: Activation function used\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "      cum_epoch_loss = 0\n",
    "\n",
    "      for batch, (images, labels) in enumerate(train_loader,1):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logps = model(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(train_loader)}) : Batch loss : {loss.item()}')\n",
    "\n",
    "      print(f'Training loss : {batch_loss/len(train_loader)}')\n",
    "    \n",
    "    # Log a metric (e.g., training loss)\n",
    "    mlflow.log_metric(\"training_loss\", batch_loss / len(train_loader))\n",
    "    \n",
    "    ###########################################################333\n",
    "    \n",
    "    model.to('cpu')\n",
    "    \n",
    "    # Save the model as an artifact\n",
    "    mlflow.pytorch.log_model(model, \"models\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        #set_trace()\n",
    "        for batch, (images, labels) in enumerate(validation_loader,1):\n",
    "\n",
    "            logps = model(images)\n",
    "            output = torch.exp(logps)\n",
    "\n",
    "            pred = torch.argmax(output, 1)\n",
    "            total += labels.size(0)\n",
    "            num_correct += (pred == labels).sum().item()\n",
    "            print(f'Batch ({batch}/{len(validation_loader)})')\n",
    "\n",
    "            # if batch == 5:\n",
    "             # break\n",
    "\n",
    "        # Calculate test accuracy\n",
    "        test_accuracy = num_correct * 100 / total\n",
    "        print(f'Accuracy of the model on {total} test images: {test_accuracy}% ')\n",
    "\n",
    "        # Log the test accuracy as a metric\n",
    "        mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "\n",
    "# fetch the auto logged parameters and metrics\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
