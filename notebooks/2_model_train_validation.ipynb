{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc50f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pyarrow pillow --upgrade --user\n",
    "# !pip3 install mlflow\n",
    "import pyarrow.parquet as pq\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import mlflow.pytorch\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c7fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=parent_directory + '/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0d01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set MLFLOW_TRACKING_USERNAME and MLFLOW_TRACKING_PASSWORD\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = os.getenv('MLFLOW_TRACKING_USERNAME')\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = os.getenv('MLFLOW_TRACKING_PASSWORD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ffdb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"CNN-pytorch\")\n",
    "mlflow.pytorch.autolog\n",
    "mlflow.set_tracking_uri('https://dagshub.com/wwoszczek/MLOps-TeamBeans.mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ebeaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(f\"run_id: {r.info.run_id}\")\n",
    "    print(f\"artifacts: {artifacts}\")\n",
    "    print(f\"params: {r.data.params}\")\n",
    "    print(f\"metrics: {r.data.metrics}\")\n",
    "    print(f\"tags: {tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43873a",
   "metadata": {},
   "source": [
    "#### Copying the class of CustomDataset as it cannot be imported easily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7235c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa453f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_file_path', 'image', 'labels'],\n",
       "    num_rows: 1034\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "dataset_train = Dataset.from_file(os.path.join(current_directory, \"raw/train/\") + \"data-00000-of-00001.arrow\")\n",
    "\n",
    "dataset_validation = Dataset.from_file(os.path.join(current_directory, \"raw/validation/\") + \"data-00000-of-00001.arrow\")\n",
    "\n",
    "dataset_test = Dataset.from_file(os.path.join(current_directory, \"raw/test/\") + \"data-00000-of-00001.arrow\")\n",
    "\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3b6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((500,500)),  # Resize to our desired size\n",
    "            transforms.ToTensor(),          # Convert PIL Image to PyTorch tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize RGB channels\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        image = self.transform(sample['image'])\n",
    "        label = sample['labels']\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "custom_train = CustomDataset(dataset_train)\n",
    "custom_validation = CustomDataset(dataset_validation)\n",
    "custom_test = CustomDataset(dataset_test)\n",
    "\n",
    "# Create a DataLoader for training, validation and test\n",
    "train_loader = DataLoader(custom_train, batch_size=32, shuffle=True)    \n",
    "validation_loader = DataLoader(custom_validation, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(custom_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc10e0",
   "metadata": {},
   "source": [
    "#### End of the copied part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bada0173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataLoader from the file\n",
    "train_loader = torch.load('dataloaders/train_loader.pt')\n",
    "validation_loader= torch.load('dataloaders/validation_loader.pt')\n",
    "test_loader = torch.load('dataloaders/test_loader.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a575ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5218723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 500, 500]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "  print(images.size(), labels.size())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a330afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNNReducedStride10(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(SimpleCNNReducedStride10, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout for regularization\n",
    "        \n",
    "        # Calculate the correct input size for fc1 based on the spatial dimensions\n",
    "        self.fc1_input_size = self.calculate_fc1_input_size()\n",
    "        self.fc1 = nn.Linear(250000, 256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(0.5)  # Add dropout for regularization\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)  # Softmax activation for classification\n",
    "\n",
    "    def calculate_fc1_input_size(self):\n",
    "        # Assuming the output size after the second convolutional layer\n",
    "        # with stride 10 is (16, 50, 50), calculate the input size for fc1\n",
    "        return 16 * 50 * 50\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten the feature maps\n",
    "        x = self.dropout(x)  # Apply dropout for regularization\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = self.log_softmax(x)  # Apply softmax for classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6eac7b",
   "metadata": {},
   "source": [
    "#### Code Restructured to fit MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2724aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:30:30] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 12:30:30] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 12:30:30] No GPU found.\n",
      "[codecarbon INFO @ 12:30:30] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 12:30:30] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 12:30:32] CPU Model on constant consumption mode: Apple M1\n",
      "[codecarbon INFO @ 12:30:32] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 12:30:32]   Platform system: macOS-10.16-x86_64-i386-64bit\n",
      "[codecarbon INFO @ 12:30:32]   Python version: 3.9.16\n",
      "[codecarbon INFO @ 12:30:32]   CodeCarbon version: 2.3.1\n",
      "[codecarbon INFO @ 12:30:32]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 12:30:32]   CPU count: 8\n",
      "[codecarbon INFO @ 12:30:32]   CPU model: Apple M1\n",
      "[codecarbon INFO @ 12:30:32]   GPU count: None\n",
      "[codecarbon INFO @ 12:30:32]   GPU model: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters in the reduced model: 64002419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:30:50] Energy consumed for RAM : 0.000025 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:30:50] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:30:50] 0.000046 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(1/33) : Batch loss : 1.1032708883285522\n",
      "Epoch(0/5 : Batch number(2/33) : Batch loss : 8.681684494018555\n",
      "Epoch(0/5 : Batch number(3/33) : Batch loss : 17.68633270263672\n",
      "Epoch(0/5 : Batch number(4/33) : Batch loss : 8.56124496459961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:31:05] Energy consumed for RAM : 0.000050 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:31:05] Energy consumed for all CPUs : 0.000042 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:31:05] 0.000092 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(5/33) : Batch loss : 9.949642181396484\n",
      "Epoch(0/5 : Batch number(6/33) : Batch loss : 4.945017337799072\n",
      "Epoch(0/5 : Batch number(7/33) : Batch loss : 3.6156108379364014\n",
      "Epoch(0/5 : Batch number(8/33) : Batch loss : 3.332427740097046\n",
      "Epoch(0/5 : Batch number(9/33) : Batch loss : 4.15415096282959\n",
      "Epoch(0/5 : Batch number(10/33) : Batch loss : 1.5108911991119385\n",
      "Epoch(0/5 : Batch number(11/33) : Batch loss : 2.12992525100708\n",
      "Epoch(0/5 : Batch number(12/33) : Batch loss : 1.7299920320510864\n",
      "Epoch(0/5 : Batch number(13/33) : Batch loss : 1.1807994842529297\n",
      "Epoch(0/5 : Batch number(14/33) : Batch loss : 1.136710524559021\n",
      "Epoch(0/5 : Batch number(15/33) : Batch loss : 1.57962965965271\n",
      "Epoch(0/5 : Batch number(16/33) : Batch loss : 1.242238163948059\n",
      "Epoch(0/5 : Batch number(17/33) : Batch loss : 1.8375751972198486\n",
      "Epoch(0/5 : Batch number(18/33) : Batch loss : 1.1355133056640625\n",
      "Epoch(0/5 : Batch number(19/33) : Batch loss : 1.243472933769226\n",
      "Epoch(0/5 : Batch number(20/33) : Batch loss : 0.9567112326622009\n",
      "Epoch(0/5 : Batch number(21/33) : Batch loss : 1.0064047574996948\n",
      "Epoch(0/5 : Batch number(22/33) : Batch loss : 0.9951290488243103\n",
      "Epoch(0/5 : Batch number(23/33) : Batch loss : 0.8358569145202637\n",
      "Epoch(0/5 : Batch number(24/33) : Batch loss : 0.7108309864997864\n",
      "Epoch(0/5 : Batch number(25/33) : Batch loss : 0.794844388961792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:31:20] Energy consumed for RAM : 0.000075 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:31:20] Energy consumed for all CPUs : 0.000063 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:31:20] 0.000138 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/5 : Batch number(26/33) : Batch loss : 0.9880395531654358\n",
      "Epoch(0/5 : Batch number(27/33) : Batch loss : 1.1031184196472168\n",
      "Epoch(0/5 : Batch number(28/33) : Batch loss : 0.943703293800354\n",
      "Epoch(0/5 : Batch number(29/33) : Batch loss : 0.950993537902832\n",
      "Epoch(0/5 : Batch number(30/33) : Batch loss : 0.7121565341949463\n",
      "Epoch(0/5 : Batch number(31/33) : Batch loss : 0.7780579924583435\n",
      "Epoch(0/5 : Batch number(32/33) : Batch loss : 0.9026592373847961\n",
      "Epoch(0/5 : Batch number(33/33) : Batch loss : 0.8431313633918762\n",
      "Training loss : 2.7053868824785408\n",
      "Epoch(1/5 : Batch number(1/33) : Batch loss : 0.7164559364318848\n",
      "Epoch(1/5 : Batch number(2/33) : Batch loss : 0.8443436622619629\n",
      "Epoch(1/5 : Batch number(3/33) : Batch loss : 0.7264710068702698\n",
      "Epoch(1/5 : Batch number(4/33) : Batch loss : 0.7730615735054016\n",
      "Epoch(1/5 : Batch number(5/33) : Batch loss : 0.8316967487335205\n",
      "Epoch(1/5 : Batch number(6/33) : Batch loss : 0.6996161937713623\n",
      "Epoch(1/5 : Batch number(7/33) : Batch loss : 0.7088679671287537\n",
      "Epoch(1/5 : Batch number(8/33) : Batch loss : 0.7558163404464722\n",
      "Epoch(1/5 : Batch number(9/33) : Batch loss : 0.6617560386657715\n",
      "Epoch(1/5 : Batch number(10/33) : Batch loss : 0.7759065628051758\n",
      "Epoch(1/5 : Batch number(11/33) : Batch loss : 0.6826751828193665\n",
      "Epoch(1/5 : Batch number(12/33) : Batch loss : 0.6589731574058533\n",
      "Epoch(1/5 : Batch number(13/33) : Batch loss : 0.7328941822052002\n",
      "Epoch(1/5 : Batch number(14/33) : Batch loss : 0.707474410533905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:31:35] Energy consumed for RAM : 0.000100 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:31:35] Energy consumed for all CPUs : 0.000083 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:31:35] 0.000183 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1/5 : Batch number(15/33) : Batch loss : 0.4601144790649414\n",
      "Epoch(1/5 : Batch number(16/33) : Batch loss : 0.8158549666404724\n",
      "Epoch(1/5 : Batch number(17/33) : Batch loss : 0.6224368214607239\n",
      "Epoch(1/5 : Batch number(18/33) : Batch loss : 0.5785641074180603\n",
      "Epoch(1/5 : Batch number(19/33) : Batch loss : 0.8406524658203125\n",
      "Epoch(1/5 : Batch number(20/33) : Batch loss : 0.8701222538948059\n",
      "Epoch(1/5 : Batch number(21/33) : Batch loss : 0.7737691402435303\n",
      "Epoch(1/5 : Batch number(22/33) : Batch loss : 0.621467649936676\n",
      "Epoch(1/5 : Batch number(23/33) : Batch loss : 0.4303314685821533\n",
      "Epoch(1/5 : Batch number(24/33) : Batch loss : 0.8688157796859741\n",
      "Epoch(1/5 : Batch number(25/33) : Batch loss : 0.6485916376113892\n",
      "Epoch(1/5 : Batch number(26/33) : Batch loss : 0.7435510754585266\n",
      "Epoch(1/5 : Batch number(27/33) : Batch loss : 0.6062349081039429\n",
      "Epoch(1/5 : Batch number(28/33) : Batch loss : 0.8434065580368042\n",
      "Epoch(1/5 : Batch number(29/33) : Batch loss : 0.9028676748275757\n",
      "Epoch(1/5 : Batch number(30/33) : Batch loss : 0.6496466994285583\n",
      "Epoch(1/5 : Batch number(31/33) : Batch loss : 0.6206940412521362\n",
      "Epoch(1/5 : Batch number(32/33) : Batch loss : 0.5541226267814636\n",
      "Epoch(1/5 : Batch number(33/33) : Batch loss : 0.6620326638221741\n",
      "Training loss : 3.4141531243468775\n",
      "Epoch(2/5 : Batch number(1/33) : Batch loss : 0.7681058645248413\n",
      "Epoch(2/5 : Batch number(2/33) : Batch loss : 0.6881194710731506\n",
      "Epoch(2/5 : Batch number(3/33) : Batch loss : 0.5639539957046509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:31:50] Energy consumed for RAM : 0.000125 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:31:50] Energy consumed for all CPUs : 0.000104 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:31:50] 0.000229 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(2/5 : Batch number(4/33) : Batch loss : 0.5731231570243835\n",
      "Epoch(2/5 : Batch number(5/33) : Batch loss : 0.6521650552749634\n",
      "Epoch(2/5 : Batch number(6/33) : Batch loss : 0.44537317752838135\n",
      "Epoch(2/5 : Batch number(7/33) : Batch loss : 0.5074743032455444\n",
      "Epoch(2/5 : Batch number(8/33) : Batch loss : 0.6090075969696045\n",
      "Epoch(2/5 : Batch number(9/33) : Batch loss : 0.4427911043167114\n",
      "Epoch(2/5 : Batch number(10/33) : Batch loss : 0.4218124449253082\n",
      "Epoch(2/5 : Batch number(11/33) : Batch loss : 0.5670598149299622\n",
      "Epoch(2/5 : Batch number(12/33) : Batch loss : 0.8677162528038025\n",
      "Epoch(2/5 : Batch number(13/33) : Batch loss : 0.594919741153717\n",
      "Epoch(2/5 : Batch number(14/33) : Batch loss : 0.4712717831134796\n",
      "Epoch(2/5 : Batch number(15/33) : Batch loss : 0.40537339448928833\n",
      "Epoch(2/5 : Batch number(16/33) : Batch loss : 0.4666895270347595\n",
      "Epoch(2/5 : Batch number(17/33) : Batch loss : 0.5803255438804626\n",
      "Epoch(2/5 : Batch number(18/33) : Batch loss : 0.6848172545433044\n",
      "Epoch(2/5 : Batch number(19/33) : Batch loss : 0.7430108785629272\n",
      "Epoch(2/5 : Batch number(20/33) : Batch loss : 0.4772679805755615\n",
      "Epoch(2/5 : Batch number(21/33) : Batch loss : 0.4846300482749939\n",
      "Epoch(2/5 : Batch number(22/33) : Batch loss : 0.622053325176239\n",
      "Epoch(2/5 : Batch number(23/33) : Batch loss : 0.4373028874397278\n",
      "Epoch(2/5 : Batch number(24/33) : Batch loss : 0.4468999207019806\n",
      "Epoch(2/5 : Batch number(25/33) : Batch loss : 0.6474426984786987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:32:05] Energy consumed for RAM : 0.000150 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:32:05] Energy consumed for all CPUs : 0.000125 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:32:05] 0.000275 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(2/5 : Batch number(26/33) : Batch loss : 0.44809916615486145\n",
      "Epoch(2/5 : Batch number(27/33) : Batch loss : 0.4499499797821045\n",
      "Epoch(2/5 : Batch number(28/33) : Batch loss : 0.45773187279701233\n",
      "Epoch(2/5 : Batch number(29/33) : Batch loss : 0.534129798412323\n",
      "Epoch(2/5 : Batch number(30/33) : Batch loss : 0.49845337867736816\n",
      "Epoch(2/5 : Batch number(31/33) : Batch loss : 0.49758613109588623\n",
      "Epoch(2/5 : Batch number(32/33) : Batch loss : 0.4473966360092163\n",
      "Epoch(2/5 : Batch number(33/33) : Batch loss : 0.28474268317222595\n",
      "Training loss : 3.9531469688271033\n",
      "Epoch(3/5 : Batch number(1/33) : Batch loss : 0.2660027742385864\n",
      "Epoch(3/5 : Batch number(2/33) : Batch loss : 0.3820355236530304\n",
      "Epoch(3/5 : Batch number(3/33) : Batch loss : 0.48393529653549194\n",
      "Epoch(3/5 : Batch number(4/33) : Batch loss : 0.4726988971233368\n",
      "Epoch(3/5 : Batch number(5/33) : Batch loss : 0.37736496329307556\n",
      "Epoch(3/5 : Batch number(6/33) : Batch loss : 0.305987685918808\n",
      "Epoch(3/5 : Batch number(7/33) : Batch loss : 0.3832627236843109\n",
      "Epoch(3/5 : Batch number(8/33) : Batch loss : 0.45436686277389526\n",
      "Epoch(3/5 : Batch number(9/33) : Batch loss : 0.45189183950424194\n",
      "Epoch(3/5 : Batch number(10/33) : Batch loss : 0.3799871504306793\n",
      "Epoch(3/5 : Batch number(11/33) : Batch loss : 0.2533818781375885\n",
      "Epoch(3/5 : Batch number(12/33) : Batch loss : 0.3631732165813446\n",
      "Epoch(3/5 : Batch number(13/33) : Batch loss : 0.4335218369960785\n",
      "Epoch(3/5 : Batch number(14/33) : Batch loss : 0.3279016613960266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:32:20] Energy consumed for RAM : 0.000175 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:32:20] Energy consumed for all CPUs : 0.000146 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:32:20] 0.000321 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(3/5 : Batch number(15/33) : Batch loss : 0.2663866877555847\n",
      "Epoch(3/5 : Batch number(16/33) : Batch loss : 0.19132809340953827\n",
      "Epoch(3/5 : Batch number(17/33) : Batch loss : 0.4335502088069916\n",
      "Epoch(3/5 : Batch number(18/33) : Batch loss : 0.5001735687255859\n",
      "Epoch(3/5 : Batch number(19/33) : Batch loss : 0.28534045815467834\n",
      "Epoch(3/5 : Batch number(20/33) : Batch loss : 0.5214500427246094\n",
      "Epoch(3/5 : Batch number(21/33) : Batch loss : 0.6412971019744873\n",
      "Epoch(3/5 : Batch number(22/33) : Batch loss : 0.20630773901939392\n",
      "Epoch(3/5 : Batch number(23/33) : Batch loss : 0.4624861478805542\n",
      "Epoch(3/5 : Batch number(24/33) : Batch loss : 0.4922211170196533\n",
      "Epoch(3/5 : Batch number(25/33) : Batch loss : 0.316872239112854\n",
      "Epoch(3/5 : Batch number(26/33) : Batch loss : 0.428256630897522\n",
      "Epoch(3/5 : Batch number(27/33) : Batch loss : 0.47943782806396484\n",
      "Epoch(3/5 : Batch number(28/33) : Batch loss : 0.2839052975177765\n",
      "Epoch(3/5 : Batch number(29/33) : Batch loss : 0.4071609079837799\n",
      "Epoch(3/5 : Batch number(30/33) : Batch loss : 0.42388975620269775\n",
      "Epoch(3/5 : Batch number(31/33) : Batch loss : 0.2881145179271698\n",
      "Epoch(3/5 : Batch number(32/33) : Batch loss : 0.333656370639801\n",
      "Epoch(3/5 : Batch number(33/33) : Batch loss : 0.24969808757305145\n",
      "Training loss : 4.333360457059109\n",
      "Epoch(4/5 : Batch number(1/33) : Batch loss : 0.37498584389686584\n",
      "Epoch(4/5 : Batch number(2/33) : Batch loss : 0.4346488118171692\n",
      "Epoch(4/5 : Batch number(3/33) : Batch loss : 0.26869937777519226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:32:35] Energy consumed for RAM : 0.000200 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:32:35] Energy consumed for all CPUs : 0.000167 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:32:35] 0.000367 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(4/5 : Batch number(4/33) : Batch loss : 0.16689413785934448\n",
      "Epoch(4/5 : Batch number(5/33) : Batch loss : 0.2981552183628082\n",
      "Epoch(4/5 : Batch number(6/33) : Batch loss : 0.2131558656692505\n",
      "Epoch(4/5 : Batch number(7/33) : Batch loss : 0.1968216598033905\n",
      "Epoch(4/5 : Batch number(8/33) : Batch loss : 0.24638059735298157\n",
      "Epoch(4/5 : Batch number(9/33) : Batch loss : 0.19673241674900055\n",
      "Epoch(4/5 : Batch number(10/33) : Batch loss : 0.3197627067565918\n",
      "Epoch(4/5 : Batch number(11/33) : Batch loss : 0.1870102435350418\n",
      "Epoch(4/5 : Batch number(12/33) : Batch loss : 0.40044042468070984\n",
      "Epoch(4/5 : Batch number(13/33) : Batch loss : 0.3342527151107788\n",
      "Epoch(4/5 : Batch number(14/33) : Batch loss : 0.19628506898880005\n",
      "Epoch(4/5 : Batch number(15/33) : Batch loss : 0.4891667664051056\n",
      "Epoch(4/5 : Batch number(16/33) : Batch loss : 0.15754839777946472\n",
      "Epoch(4/5 : Batch number(17/33) : Batch loss : 0.28802290558815\n",
      "Epoch(4/5 : Batch number(18/33) : Batch loss : 0.27207085490226746\n",
      "Epoch(4/5 : Batch number(19/33) : Batch loss : 0.20802198350429535\n",
      "Epoch(4/5 : Batch number(20/33) : Batch loss : 0.1881035417318344\n",
      "Epoch(4/5 : Batch number(21/33) : Batch loss : 0.2876938581466675\n",
      "Epoch(4/5 : Batch number(22/33) : Batch loss : 0.3966769576072693\n",
      "Epoch(4/5 : Batch number(23/33) : Batch loss : 0.2384680211544037\n",
      "Epoch(4/5 : Batch number(24/33) : Batch loss : 0.3731033504009247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:32:50] Energy consumed for RAM : 0.000225 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:32:50] Energy consumed for all CPUs : 0.000188 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:32:50] 0.000412 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(4/5 : Batch number(25/33) : Batch loss : 0.23487934470176697\n",
      "Epoch(4/5 : Batch number(26/33) : Batch loss : 0.2640286982059479\n",
      "Epoch(4/5 : Batch number(27/33) : Batch loss : 0.24720129370689392\n",
      "Epoch(4/5 : Batch number(28/33) : Batch loss : 0.2319091409444809\n",
      "Epoch(4/5 : Batch number(29/33) : Batch loss : 0.2174258679151535\n",
      "Epoch(4/5 : Batch number(30/33) : Batch loss : 0.17638926208019257\n",
      "Epoch(4/5 : Batch number(31/33) : Batch loss : 0.27261438965797424\n",
      "Epoch(4/5 : Batch number(32/33) : Batch loss : 0.10507487505674362\n",
      "Epoch(4/5 : Batch number(33/33) : Batch loss : 0.3637768626213074\n",
      "Training loss : 4.601433228588466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateuszgalinski/opt/anaconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "[codecarbon INFO @ 12:33:05] Energy consumed for RAM : 0.000250 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:33:05] Energy consumed for all CPUs : 0.000208 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:33:05] 0.000458 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:33:20] Energy consumed for RAM : 0.000275 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:33:20] Energy consumed for all CPUs : 0.000229 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:33:20] 0.000504 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:33:35] Energy consumed for RAM : 0.000300 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:33:35] Energy consumed for all CPUs : 0.000250 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:33:35] 0.000550 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:33:50] Energy consumed for RAM : 0.000325 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:33:50] Energy consumed for all CPUs : 0.000271 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:33:50] 0.000596 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch (1/5)\n",
      "Batch (2/5)\n",
      "Batch (3/5)\n",
      "Batch (4/5)\n",
      "Batch (5/5)\n",
      "Accuracy of the model on 133 test images: 75.93984962406014% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:33:57] Energy consumed for RAM : 0.000337 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 12:33:57] Energy consumed for all CPUs : 0.000281 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 12:33:57] 0.000618 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 1531b1f9cfce4624ab248e05042f8a15\n",
      "artifacts: []\n",
      "params: {'num_epochs': '5', 'num_classes': '3', 'stride_conv2': '2', 'kernel_size_conv2': '3', 'total_trainable_parameters': '64002419', 'kernel_size_conv1': '3', 'dropout_rate': '0.5', 'fc1_input_size': '40000', 'padding_conv1': '1', 'stride_conv1': '2', 'padding_conv2': '1', 'num_conv_layers': '2', 'activation_function': 'ReLU'}\n",
      "metrics: {'test_accuracy': 75.9398496240601, 'training_loss': 4.60143322858847}\n",
      "tags: {}\n"
     ]
    }
   ],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "try:\n",
    "  with mlflow.start_run() as run:\n",
    "    ## The idea is to get the autolog to run for our pytorch funct. \n",
    "    ## It might depend on the funct. we choose and the pytorch version\n",
    "    ## Thus initially I defined some metrics to try it.\n",
    "    \n",
    "    # Create an instance of the SimpleCNNReduced model\n",
    "    model = SimpleCNNReducedStride10(num_classes=3)\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # Calculate the total number of trainable parameters\n",
    "    total_params_reduced = count_parameters(model)\n",
    "    mlflow.log_param(\"total_trainable_parameters\", total_params_reduced)\n",
    "    print(f\"Total trainable parameters in the reduced model: {total_params_reduced}\")\n",
    "    \n",
    "    ###############################3\n",
    "    \n",
    "    from torch.optim import Adam\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters())\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    num_epochs = 5\n",
    "    batch_loss = 0\n",
    "    cum_epoch_loss = 0\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"num_classes\", 3)\n",
    "    mlflow.log_param(\"kernel_size_conv1\", 3)\n",
    "    mlflow.log_param(\"stride_conv1\", 2)\n",
    "    mlflow.log_param(\"padding_conv1\", 1)\n",
    "    mlflow.log_param(\"kernel_size_conv2\", 3)\n",
    "    mlflow.log_param(\"stride_conv2\", 2)\n",
    "    mlflow.log_param(\"padding_conv2\", 1)\n",
    "    mlflow.log_param(\"dropout_rate\", 0.5)\n",
    "    mlflow.log_param(\"fc1_input_size\", model.fc1_input_size)\n",
    "    mlflow.log_param(\"num_conv_layers\", 2)  # Example: Number of convolutional layers\n",
    "    mlflow.log_param(\"activation_function\", \"ReLU\")  # Example: Activation function used\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "      cum_epoch_loss = 0\n",
    "\n",
    "      for batch, (images, labels) in enumerate(train_loader,1):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logps = model(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(train_loader)}) : Batch loss : {loss.item()}')\n",
    "\n",
    "      print(f'Training loss : {batch_loss/len(train_loader)}')\n",
    "    \n",
    "    # Log a metric (e.g., training loss)\n",
    "    mlflow.log_metric(\"training_loss\", batch_loss / len(train_loader))\n",
    "    \n",
    "    ###########################################################333\n",
    "    \n",
    "    model.to('cpu')\n",
    "    \n",
    "    # Save the model as an artifact\n",
    "    mlflow.pytorch.log_model(model, \"models\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        #set_trace()\n",
    "        for batch, (images, labels) in enumerate(validation_loader,1):\n",
    "\n",
    "            logps = model(images)\n",
    "            output = torch.exp(logps)\n",
    "\n",
    "            pred = torch.argmax(output, 1)\n",
    "            total += labels.size(0)\n",
    "            num_correct += (pred == labels).sum().item()\n",
    "            print(f'Batch ({batch}/{len(validation_loader)})')\n",
    "\n",
    "            # if batch == 5:\n",
    "             # break\n",
    "\n",
    "        # Calculate test accuracy\n",
    "        test_accuracy = num_correct * 100 / total\n",
    "        print(f'Accuracy of the model on {total} test images: {test_accuracy}% ')\n",
    "\n",
    "        # Log the test accuracy as a metric\n",
    "        mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "finally:\n",
    "  tracker.stop()\n",
    "  \n",
    "# fetch the auto logged parameters and metrics\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
